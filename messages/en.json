{
  "header": {
    "title": "Xinference",
    "nav": {
      "features": "Features",
      "pricing": "Pricing",
      "docs": "Documentation",
      "contact": "Contact Us"
    },
    "cta": {
      "enterprise": "Enterprise",
      "compare": "Compare",
      "partner": "Partner"
    }
  },
  "hero": {
    "title": {
      "line1": "Deploy AI Models",
      "line2": "Fast And Seamless",
      "line3": "Enterprise Ready"
    },
    "subtitle": "Any Model, Any Hardware, Peak Performance.",
    "description": "Effortlessly deploy, manage, and scale LLMs, multimodal, and speech models with our enterprise-grade, full-stack inference platform. Your infrastructure, your models, optimized.",
    "features": "Model lifecycle management, multiple inference engines, heterogeneous GPUs, high throughput and availability, efficient scheduling",
    "cta": {
      "trial": "Request Trial",
      "demo": "Watch Demo"
    },
    "stats": {
      "githubStars": "GitHub Stars",
      "globalDeployments": "Global Deployments",
      "enterpriseUsers": "Enterprise Users"
    },
    "dashboard": {
      "webDevelopment": {
        "title": "Web Development",
        "description": "Lorem ipsum dolor sit amet consectetur adipiscing elit. Omnis tempore perferendis explicabo."
      },
      "digitalMarketing": {
        "title": "Digital Marketing",
        "description": "Lorem ipsum dolor sit amet consectetur adipiscing elit. Omnis tempore perferendis explicabo."
      },
      "saasProducts": {
        "title": "SaaS Products",
        "description": "Lorem ipsum dolor sit amet consectetur adipiscing elit. Omnis tempore perferendis explicabo."
      },
      "appsDevelopment": {
        "title": "Apps Development",
        "description": "Lorem ipsum dolor sit amet consectetur adipiscing elit. Omnis tempore perferendis explicabo."
      },
      "seoServices": {
        "title": "SEO Services",
        "description": "Lorem ipsum dolor sit amet consectetur adipiscing elit. Omnis tempore perferendis explicabo."
      },
      "dataAnalysis": {
        "title": "Data Analysis",
        "description": "Lorem ipsum dolor sit amet consectetur adipiscing elit. Omnis tempore perferendis explicabo."
      },
      "readMore": "Read More"
    },
    "tags": {
      "performance": "High Performance",
      "easyDeploy": "Easy Deploy",
      "monitoring": "Monitorable",
      "secure": "Secure & Reliable"
    }
  },
  "features": {
    "section": {
      "badge": "Xinference Core Advantages",
      "title": "Enterprise-grade AI deployment platform designed to solve large-scale implementation challenges",
      "description": "Comprehensive AI inference service solution providing powerful AI capability support for your applications"
    },
    "engines": {
      "title": "Multi-Engine Concurrent Inference",
      "description": "Support vLLM, SGLang, Transformer, MLX and other engines to start simultaneously, providing large-scale multi-feature inference services for enterprises."
    },
    "hardware": {
      "title": "Extensive Computing Power Support",
      "description": "Comprehensive adaptation of mainstream computing chips at home and abroad: NVIDIA, Ascend, Intel, Cambricon, Hygon and other heterogeneous hardware."
    },
    "performance": {
      "title": "Enterprise-grade Distributed Deployment",
      "description": "Based on self-developed Xoscar high-performance distributed computing foundation, supporting stable operation at 200,000-core scale with automatic load balancing and fault recovery capabilities."
    },
    "models": {
      "title": "Comprehensive Model Repository",
      "description": "Integrating 100+ latest models, including mainstream models like deepseek, Qwen3, InternVL, supporting voice, multimodal and other model types."
    },
    "enterprise": {
      "title": "Enterprise-grade Management Functions",
      "description": "Providing fine-tuning support, permission management, monitoring systems, batch processing and other enterprise-grade functions to meet professional domain requirements in finance, healthcare, etc."
    },
    "concurrency": {
      "title": "High Concurrency Optimization",
      "description": "Optimized for enterprise high-concurrency scenarios, supports structured output, provides memory optimization and performance acceleration, ensuring business continuity and stability."
    },
    "cta": {
      "title": "Ready to Start Your AI Journey?",
      "description": "Experience the powerful AI inference capabilities of Xinference now",
      "button": "Get Started"
    }
  },
  "openSource": {
    "title": "Open Source & Free to Use",
    "description": "Xinference is an open-source project that's free to use, customize, and extend according to your needs."
  },
  "github": {
    "star": "Star on GitHub"
  },
  "footer": {
    "copyright": "Copyright © 2024 Hangzhou Future Speed Technology Co., Ltd.",
    "icp": "浙ICP备2022033013号",
    "security": "浙公网安备：33011002016954"
  }
}